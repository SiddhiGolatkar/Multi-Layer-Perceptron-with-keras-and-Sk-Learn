{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with Keras and Scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "\n",
    "    Keras is a high-level neural networks library, written in Python and capable of running on top of either TensorFlow, CNTK or Theano. Allows for easy and fast prototyping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current working directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set directory to the place where csv file exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pima indians dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
      " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
      " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
      " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
      " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate independent variables(X) and target variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0:8]\n",
    "y = data[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn package, split X and y into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shapes of the new X objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8)\n",
      "(192, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shapes of the new y objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576,)\n",
      "(192,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Models in Keras are defined as a sequence of layers.\n",
    "\n",
    "2. First sequential model is created and layers are added one at a time. \n",
    "\n",
    "__Note__:The best network structure is found through a process of trial and error experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build a fully-connected network structure with two layers.\n",
    "\n",
    "    The first layer has 12 neurons and expects 8 input variables. \n",
    "    Finally the output layer has 1 neuron to predict the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequential model is a linear stack of layers. \n",
    "Sequential model is created by passing a list of layer instances to the constructor or by simply add layers via the .add() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(12, input_dim=8, activation='tanh', kernel_initializer='uniform'))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True).\n",
    "\n",
    "\n",
    "Note: If the input to the layer has a rank greater than 2, then it is flattened prior to the initial dot product with kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully connected layers are defined using the Dense class. \n",
    "\n",
    "We specify \n",
    "    1. The number of neurons in the layer as the first argument\n",
    "    2. The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape. One way is using input_dim argument. \n",
    "    3. The activation function using the activation argument. ‘tanh‘ activation function is used in first layer and the sigmoid activiation function in the output layer. \n",
    "    4. Initializations define the way to set the initial random weights of Keras layers. We initialize the network weights to a small random number generated from a uniform distribution (‘uniform‘).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training a model, you need to configure the learning process, which is done via the compile method. It receives three arguments:\n",
    "\n",
    "    an optimizer     : This could be the string identifier of an existing optimizer (such as rmsprop or adagrad or sgd), or an instance of the Optimizer class.\n",
    "    \n",
    "    a loss function  : This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as categorical_crossentropy or mse), or it can be an objective function.\n",
    "    \n",
    "    a list of metrics: For any classification problem you will want to set this to metrics=['accuracy']. A metric could be the string identifier of an existing metric or a custom metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the fit function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.6233\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6493\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6493\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6493\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.6493\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.6493\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6361 - accuracy: 0.6493\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6493\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.6493\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6493\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.6493\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.6493\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6493\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.6493\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6493\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.6493\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6493\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.6493\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.6493\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6493\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6646 - accuracy: 0.56 - 0s 1ms/step - loss: 0.6254 - accuracy: 0.6493\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6493\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.6493\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.6493\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6493\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6493\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6493\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.6493\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6493\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6493\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6493\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6259 - accuracy: 0.6493\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6493\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6238 - accuracy: 0.6493\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6493\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6190 - accuracy: 0.6493\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6493\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6493\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6214 - accuracy: 0.6493\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6493\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.6476\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.6493\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6476\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6424\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.6493\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6476\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6476\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6493\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6493\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6476\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6493\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6476\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6493\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6458\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.6493\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6493\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6092 - accuracy: 0.6476\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6476\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6493\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6493\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6109 - accuracy: 0.6458\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6424\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6458\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6143 - accuracy: 0.6458\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6441\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6441\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6127 - accuracy: 0.6493\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.6493\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6137 - accuracy: 0.6493\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6493\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.6493\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6167 - accuracy: 0.6493\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6372\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.6441\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6476\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6493\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6406\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6441\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.6441\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.6389\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6441\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6476\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.6493\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6424\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6069 - accuracy: 0.6476\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.6493\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6476\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.6441\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6597\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.6632\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6125 - accuracy: 0.6389\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6458\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6597\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.6597\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6615\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.6562\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5984 - accuracy: 0.6615\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.6545\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.6562\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.6528\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6615\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.6528\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6458\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.6476\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.6667\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.6528\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6597\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6701\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6684\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6649\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6424\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.6389\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.6615\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6055 - accuracy: 0.6389\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6054 - accuracy: 0.6580\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6840\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6719\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5987 - accuracy: 0.6580\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6372\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5973 - accuracy: 0.6736\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6021 - accuracy: 0.6788\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.6910\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6701\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6441\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.6337\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6004 - accuracy: 0.6632\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6021 - accuracy: 0.6545\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.6840\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.6632\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6892\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5934 - accuracy: 0.6858\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.6788\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.6840\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6753\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.6840\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5905 - accuracy: 0.6771\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5961 - accuracy: 0.6910\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.6806\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.6649\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5992 - accuracy: 0.6771\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6997\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.6736\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5934 - accuracy: 0.6788\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5928 - accuracy: 0.6806\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.6927\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.6684\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6684\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5947 - accuracy: 0.6788\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5920 - accuracy: 0.6892\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.6823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x185c79cb448>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    x         : input data, as a Numpy array or list of Numpy arrays (if the model has multiple inputs).\n",
    "    y         : labels, as a Numpy array.\n",
    "    batch_size: integer. Number of samples per gradient update.\n",
    "    epochs  : integer, the number of epochs to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we trained neural network on the entire dataset and evaluating its on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.6823\n",
      "accuracy: 68.23%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_train, y_train)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict using model.predict().  \n",
    "We are using a sigmoid activation function in the output layer, so the predictions will be in the range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.195761  ]\n",
      " [0.49219352]\n",
      " [0.4210707 ]\n",
      " [0.5469434 ]\n",
      " [0.19346994]\n",
      " [0.4211488 ]\n",
      " [0.42112833]\n",
      " [0.37276942]\n",
      " [0.276219  ]\n",
      " [0.1759457 ]\n",
      " [0.13744393]\n",
      " [0.13740769]\n",
      " [0.19481269]\n",
      " [0.20040697]\n",
      " [0.54694366]\n",
      " [0.4211499 ]\n",
      " [0.43142092]\n",
      " [0.22874281]\n",
      " [0.29276362]\n",
      " [0.13738295]\n",
      " [0.42115158]\n",
      " [0.14066193]\n",
      " [0.13741687]\n",
      " [0.37556252]\n",
      " [0.13741863]\n",
      " [0.21068338]\n",
      " [0.13740164]\n",
      " [0.28900567]\n",
      " [0.33304685]\n",
      " [0.4697164 ]\n",
      " [0.5204098 ]\n",
      " [0.3788188 ]\n",
      " [0.13740858]\n",
      " [0.46039674]\n",
      " [0.56313866]\n",
      " [0.42100343]\n",
      " [0.17669639]\n",
      " [0.30771875]\n",
      " [0.5103881 ]\n",
      " [0.13843304]\n",
      " [0.51439595]\n",
      " [0.13738966]\n",
      " [0.42114624]\n",
      " [0.13741016]\n",
      " [0.5264    ]\n",
      " [0.31213593]\n",
      " [0.1378726 ]\n",
      " [0.54694355]\n",
      " [0.4041087 ]\n",
      " [0.42114788]\n",
      " [0.42230967]\n",
      " [0.23025608]\n",
      " [0.3363743 ]\n",
      " [0.24348539]\n",
      " [0.53960526]\n",
      " [0.2882223 ]\n",
      " [0.42114976]\n",
      " [0.14573932]\n",
      " [0.13831863]\n",
      " [0.5061579 ]\n",
      " [0.36982164]\n",
      " [0.1457229 ]\n",
      " [0.15722752]\n",
      " [0.37197968]\n",
      " [0.13892588]\n",
      " [0.5030569 ]\n",
      " [0.13921961]\n",
      " [0.40295753]\n",
      " [0.14102083]\n",
      " [0.4211402 ]\n",
      " [0.27569395]\n",
      " [0.42031956]\n",
      " [0.5253787 ]\n",
      " [0.5049025 ]\n",
      " [0.33417815]\n",
      " [0.42114076]\n",
      " [0.13741797]\n",
      " [0.5469395 ]\n",
      " [0.5257853 ]\n",
      " [0.13748002]\n",
      " [0.42111015]\n",
      " [0.20133838]\n",
      " [0.4211434 ]\n",
      " [0.28132588]\n",
      " [0.37168986]\n",
      " [0.41997677]\n",
      " [0.4211495 ]\n",
      " [0.5263022 ]\n",
      " [0.28183198]\n",
      " [0.15800354]\n",
      " [0.1457926 ]\n",
      " [0.4211504 ]\n",
      " [0.37489444]\n",
      " [0.42115083]\n",
      " [0.4211498 ]\n",
      " [0.137402  ]\n",
      " [0.41235307]\n",
      " [0.36757928]\n",
      " [0.42098308]\n",
      " [0.13740772]\n",
      " [0.13741738]\n",
      " [0.3809955 ]\n",
      " [0.40541792]\n",
      " [0.42602983]\n",
      " [0.34899354]\n",
      " [0.27885967]\n",
      " [0.14880547]\n",
      " [0.13757533]\n",
      " [0.21814069]\n",
      " [0.38765436]\n",
      " [0.26127362]\n",
      " [0.42115027]\n",
      " [0.13746747]\n",
      " [0.4627273 ]\n",
      " [0.14563537]\n",
      " [0.2980555 ]\n",
      " [0.13745391]\n",
      " [0.42113686]\n",
      " [0.22811624]\n",
      " [0.28413063]\n",
      " [0.13741007]\n",
      " [0.41342685]\n",
      " [0.13739893]\n",
      " [0.3434908 ]\n",
      " [0.14084956]\n",
      " [0.13740787]\n",
      " [0.5264944 ]\n",
      " [0.14052263]\n",
      " [0.14047685]\n",
      " [0.50266916]\n",
      " [0.23545533]\n",
      " [0.4211543 ]\n",
      " [0.1429061 ]\n",
      " [0.13741475]\n",
      " [0.14093128]\n",
      " [0.24284336]\n",
      " [0.2840619 ]\n",
      " [0.52642083]\n",
      " [0.23779446]\n",
      " [0.24014786]\n",
      " [0.42115134]\n",
      " [0.42116073]\n",
      " [0.27985573]\n",
      " [0.2350465 ]\n",
      " [0.2815026 ]\n",
      " [0.28315744]\n",
      " [0.23499969]\n",
      " [0.415711  ]\n",
      " [0.525937  ]\n",
      " [0.37378716]\n",
      " [0.25171703]\n",
      " [0.52647823]\n",
      " [0.14247999]\n",
      " [0.13741091]\n",
      " [0.42113543]\n",
      " [0.42110306]\n",
      " [0.27722353]\n",
      " [0.20336539]\n",
      " [0.5263806 ]\n",
      " [0.47554246]\n",
      " [0.13790995]\n",
      " [0.40262955]\n",
      " [0.2408534 ]\n",
      " [0.41939294]\n",
      " [0.42111742]\n",
      " [0.5264111 ]\n",
      " [0.5469435 ]\n",
      " [0.31338847]\n",
      " [0.138542  ]\n",
      " [0.25138706]\n",
      " [0.51123464]\n",
      " [0.5256695 ]\n",
      " [0.25831324]\n",
      " [0.16370857]\n",
      " [0.32915348]\n",
      " [0.21641695]\n",
      " [0.37292638]\n",
      " [0.13762814]\n",
      " [0.42112583]\n",
      " [0.37468916]\n",
      " [0.14700365]\n",
      " [0.4211509 ]\n",
      " [0.18745908]\n",
      " [0.5077701 ]\n",
      " [0.5115129 ]\n",
      " [0.5262588 ]\n",
      " [0.33564365]\n",
      " [0.13748327]\n",
      " [0.42112908]\n",
      " [0.30510646]\n",
      " [0.13739324]\n",
      " [0.3225333 ]\n",
      " [0.13836774]\n",
      " [0.41889596]\n",
      " [0.16565311]\n",
      " [0.4211204 ]\n",
      " [0.42114997]\n",
      " [0.52429026]\n",
      " [0.14461416]\n",
      " [0.5126811 ]\n",
      " [0.42112115]\n",
      " [0.5228108 ]\n",
      " [0.26771238]\n",
      " [0.37674382]\n",
      " [0.421146  ]\n",
      " [0.13739708]\n",
      " [0.42114723]\n",
      " [0.1391722 ]\n",
      " [0.50674075]\n",
      " [0.17239207]\n",
      " [0.4208738 ]\n",
      " [0.46400756]\n",
      " [0.4206677 ]\n",
      " [0.5241063 ]\n",
      " [0.42114928]\n",
      " [0.4175603 ]\n",
      " [0.1374076 ]\n",
      " [0.37728795]\n",
      " [0.42103714]\n",
      " [0.5469434 ]\n",
      " [0.421126  ]\n",
      " [0.45851898]\n",
      " [0.42011932]\n",
      " [0.4469637 ]\n",
      " [0.13809794]\n",
      " [0.51464653]\n",
      " [0.17385447]\n",
      " [0.21269193]\n",
      " [0.37229252]\n",
      " [0.42115015]\n",
      " [0.13750285]\n",
      " [0.1376569 ]\n",
      " [0.42122597]\n",
      " [0.40033633]\n",
      " [0.42101294]\n",
      " [0.4928866 ]\n",
      " [0.28207207]\n",
      " [0.2638191 ]\n",
      " [0.54475284]\n",
      " [0.42115387]\n",
      " [0.468791  ]\n",
      " [0.13744277]\n",
      " [0.22649994]\n",
      " [0.3807759 ]\n",
      " [0.37355894]\n",
      " [0.2846376 ]\n",
      " [0.22296289]\n",
      " [0.24982837]\n",
      " [0.4211495 ]\n",
      " [0.42114675]\n",
      " [0.4151311 ]\n",
      " [0.504124  ]\n",
      " [0.37355047]\n",
      " [0.17466325]\n",
      " [0.28952193]\n",
      " [0.52649987]\n",
      " [0.16871578]\n",
      " [0.410283  ]\n",
      " [0.13760638]\n",
      " [0.14231524]\n",
      " [0.42466697]\n",
      " [0.52619535]\n",
      " [0.36014968]\n",
      " [0.26539156]\n",
      " [0.3778864 ]\n",
      " [0.23038203]\n",
      " [0.22836182]\n",
      " [0.14490372]\n",
      " [0.35692444]\n",
      " [0.42114586]\n",
      " [0.48496488]\n",
      " [0.13747561]\n",
      " [0.4214391 ]\n",
      " [0.16387913]\n",
      " [0.23353076]\n",
      " [0.13887146]\n",
      " [0.4280686 ]\n",
      " [0.13916227]\n",
      " [0.42084494]\n",
      " [0.13741529]\n",
      " [0.42109075]\n",
      " [0.13753569]\n",
      " [0.515874  ]\n",
      " [0.25343132]\n",
      " [0.33058482]\n",
      " [0.5054551 ]\n",
      " [0.505254  ]\n",
      " [0.45748827]\n",
      " [0.45058438]\n",
      " [0.41375646]\n",
      " [0.36147428]\n",
      " [0.23280454]\n",
      " [0.421118  ]\n",
      " [0.33124125]\n",
      " [0.24874026]\n",
      " [0.13742569]\n",
      " [0.36154008]\n",
      " [0.41179702]\n",
      " [0.2872452 ]\n",
      " [0.13744727]\n",
      " [0.1392507 ]\n",
      " [0.34828413]\n",
      " [0.17057842]\n",
      " [0.4204476 ]\n",
      " [0.3502598 ]\n",
      " [0.45065033]\n",
      " [0.13750961]\n",
      " [0.20191276]\n",
      " [0.28974563]\n",
      " [0.41977954]\n",
      " [0.19750774]\n",
      " [0.52349544]\n",
      " [0.5264393 ]\n",
      " [0.3651802 ]\n",
      " [0.5063538 ]\n",
      " [0.13741043]\n",
      " [0.13976952]\n",
      " [0.14444041]\n",
      " [0.33557308]\n",
      " [0.5038108 ]\n",
      " [0.13741878]\n",
      " [0.5451296 ]\n",
      " [0.42115107]\n",
      " [0.22861424]\n",
      " [0.34984198]\n",
      " [0.54693127]\n",
      " [0.51095444]\n",
      " [0.42115176]\n",
      " [0.1375528 ]\n",
      " [0.42114908]\n",
      " [0.31397843]\n",
      " [0.19657221]\n",
      " [0.24427992]\n",
      " [0.49861115]\n",
      " [0.4210814 ]\n",
      " [0.4211998 ]\n",
      " [0.13833246]\n",
      " [0.4211111 ]\n",
      " [0.37167448]\n",
      " [0.42115152]\n",
      " [0.5264509 ]\n",
      " [0.13741419]\n",
      " [0.15288481]\n",
      " [0.33417684]\n",
      " [0.20464846]\n",
      " [0.368927  ]\n",
      " [0.26046935]\n",
      " [0.42115107]\n",
      " [0.13739762]\n",
      " [0.16052523]\n",
      " [0.4210291 ]\n",
      " [0.42115146]\n",
      " [0.4211516 ]\n",
      " [0.39920294]\n",
      " [0.28107512]\n",
      " [0.13764557]\n",
      " [0.17861107]\n",
      " [0.24808455]\n",
      " [0.5262434 ]\n",
      " [0.14164153]\n",
      " [0.42114818]\n",
      " [0.22018778]\n",
      " [0.13739774]\n",
      " [0.42115116]\n",
      " [0.40770268]\n",
      " [0.22200483]\n",
      " [0.2665706 ]\n",
      " [0.42113844]\n",
      " [0.40029752]\n",
      " [0.15374735]\n",
      " [0.4211331 ]\n",
      " [0.28099996]\n",
      " [0.23065066]\n",
      " [0.38276464]\n",
      " [0.52586067]\n",
      " [0.14472061]\n",
      " [0.526334  ]\n",
      " [0.49882028]\n",
      " [0.42109546]\n",
      " [0.5469433 ]\n",
      " [0.42112043]\n",
      " [0.28975785]\n",
      " [0.3702918 ]\n",
      " [0.23300198]\n",
      " [0.43475053]\n",
      " [0.50816125]\n",
      " [0.15590772]\n",
      " [0.42115185]\n",
      " [0.42114887]\n",
      " [0.42097434]\n",
      " [0.13909227]\n",
      " [0.14061454]\n",
      " [0.4211469 ]\n",
      " [0.42114133]\n",
      " [0.3651191 ]\n",
      " [0.4041475 ]\n",
      " [0.5050399 ]\n",
      " [0.42114323]\n",
      " [0.349164  ]\n",
      " [0.26400444]\n",
      " [0.42102137]\n",
      " [0.50449383]\n",
      " [0.525389  ]\n",
      " [0.13740775]\n",
      " [0.42082104]\n",
      " [0.3870681 ]\n",
      " [0.42108914]\n",
      " [0.50933063]\n",
      " [0.5126442 ]\n",
      " [0.4210839 ]\n",
      " [0.51553565]\n",
      " [0.14248464]\n",
      " [0.42115146]\n",
      " [0.42115802]\n",
      " [0.13739803]\n",
      " [0.16316134]\n",
      " [0.2663191 ]\n",
      " [0.5265198 ]\n",
      " [0.5259174 ]\n",
      " [0.52640617]\n",
      " [0.34921026]\n",
      " [0.32618266]\n",
      " [0.15915659]\n",
      " [0.56817687]\n",
      " [0.13740003]\n",
      " [0.29910818]\n",
      " [0.3581235 ]\n",
      " [0.42092556]\n",
      " [0.14193702]\n",
      " [0.13749138]\n",
      " [0.3572126 ]\n",
      " [0.4204654 ]\n",
      " [0.1379905 ]\n",
      " [0.4211524 ]\n",
      " [0.42116845]\n",
      " [0.13759348]\n",
      " [0.5263648 ]\n",
      " [0.42112494]\n",
      " [0.41973063]\n",
      " [0.20245674]\n",
      " [0.22643495]\n",
      " [0.13742605]\n",
      " [0.37616917]\n",
      " [0.13761568]\n",
      " [0.5057118 ]\n",
      " [0.14553371]\n",
      " [0.4211501 ]\n",
      " [0.5265085 ]\n",
      " [0.42114422]\n",
      " [0.21736163]\n",
      " [0.5025457 ]\n",
      " [0.42114788]\n",
      " [0.14248624]\n",
      " [0.13734066]\n",
      " [0.4211497 ]\n",
      " [0.21803641]\n",
      " [0.14386642]\n",
      " [0.28631267]\n",
      " [0.52606577]\n",
      " [0.18274727]\n",
      " [0.13804281]\n",
      " [0.13740128]\n",
      " [0.41821638]\n",
      " [0.5232924 ]\n",
      " [0.52610445]\n",
      " [0.5261844 ]\n",
      " [0.20498776]\n",
      " [0.13739794]\n",
      " [0.3704704 ]\n",
      " [0.42113274]\n",
      " [0.39445066]\n",
      " [0.2506283 ]\n",
      " [0.42090887]\n",
      " [0.13798851]\n",
      " [0.51758957]\n",
      " [0.13740492]\n",
      " [0.28143775]\n",
      " [0.13771716]\n",
      " [0.5261786 ]\n",
      " [0.2576713 ]\n",
      " [0.40038413]\n",
      " [0.51998895]\n",
      " [0.24639568]\n",
      " [0.5165437 ]\n",
      " [0.13741389]\n",
      " [0.5153652 ]\n",
      " [0.20771813]\n",
      " [0.34238628]\n",
      " [0.42115268]\n",
      " [0.42115068]\n",
      " [0.42116922]\n",
      " [0.14754409]\n",
      " [0.42115083]\n",
      " [0.13740337]\n",
      " [0.5254414 ]\n",
      " [0.3642049 ]\n",
      " [0.41520882]\n",
      " [0.18526515]\n",
      " [0.5251771 ]\n",
      " [0.33240336]\n",
      " [0.4213118 ]\n",
      " [0.4204647 ]\n",
      " [0.1925967 ]\n",
      " [0.4686214 ]\n",
      " [0.42121524]\n",
      " [0.42114568]\n",
      " [0.22824767]\n",
      " [0.41681036]\n",
      " [0.13815859]\n",
      " [0.4015068 ]\n",
      " [0.42261058]\n",
      " [0.4211528 ]\n",
      " [0.1432361 ]\n",
      " [0.41982996]\n",
      " [0.3081318 ]\n",
      " [0.1376673 ]\n",
      " [0.5030504 ]\n",
      " [0.42265892]\n",
      " [0.40785247]\n",
      " [0.19446135]\n",
      " [0.42114958]\n",
      " [0.13740644]\n",
      " [0.42114884]\n",
      " [0.13949925]\n",
      " [0.13740039]\n",
      " [0.13742346]\n",
      " [0.22647232]\n",
      " [0.42114878]\n",
      " [0.42113253]\n",
      " [0.26885   ]\n",
      " [0.38802803]\n",
      " [0.42118984]\n",
      " [0.23554271]\n",
      " [0.42115176]\n",
      " [0.4211191 ]\n",
      " [0.13788345]\n",
      " [0.28951353]\n",
      " [0.5055078 ]\n",
      " [0.42110085]\n",
      " [0.13745967]\n",
      " [0.13865426]\n",
      " [0.17166147]\n",
      " [0.37444577]\n",
      " [0.42115134]\n",
      " [0.4140667 ]\n",
      " [0.37306952]\n",
      " [0.4062082 ]\n",
      " [0.5262303 ]\n",
      " [0.5003801 ]\n",
      " [0.42115036]\n",
      " [0.54693526]\n",
      " [0.37661335]\n",
      " [0.14513993]\n",
      " [0.42115122]\n",
      " [0.1375817 ]\n",
      " [0.5055051 ]\n",
      " [0.21338576]\n",
      " [0.5249371 ]\n",
      " [0.13942182]\n",
      " [0.13756317]\n",
      " [0.42109272]\n",
      " [0.52456844]\n",
      " [0.5263395 ]\n",
      " [0.47048625]\n",
      " [0.26947272]\n",
      " [0.4211516 ]\n",
      " [0.1374085 ]\n",
      " [0.4420815 ]\n",
      " [0.2062566 ]\n",
      " [0.5252904 ]\n",
      " [0.42221335]\n",
      " [0.42115125]\n",
      " [0.41801748]\n",
      " [0.13961542]\n",
      " [0.13736162]\n",
      " [0.14180782]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_train)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-02713596a046>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = model.predict_classes(X_test)\n",
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy of class predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,  14],\n",
       "       [ 46,  20]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "    https://keras.io/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
